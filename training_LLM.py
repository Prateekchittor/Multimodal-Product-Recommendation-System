# -- coding: utf-8 --
"""ML_2_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MjC9Z3rLM6liVaMQrN9nQzH6uik27VCy
"""

!pip install kaggle
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json



!kaggle datasets download -d paramaggarwal/fashion-product-images-small

!unzip fashion-product-images-small.zip

import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
import os
import pandas as pd
import json

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load styles.csv

import pandas as pd
import csv

# Path to the original CSV file
csv_file_path = '/content/myntradataset/styles.csv'
# Path for the cleaned CSV file
cleaned_csv_file_path = '/content/myntradataset/styles_cleaned.csv'

# Initialize a list to hold valid rows
valid_rows = []

# Read the original CSV file and filter out problematic rows
with open(csv_file_path, 'r') as infile:
    reader = csv.reader(infile)
    for row in reader:
        # Check the number of fields
        if len(row) == 10:  # Adjust this to the expected number of columns
            valid_rows.append(row)
        else:
            print(f"Removing problematic row: {row}")  # Log problematic rows

# Write the valid rows to a new cleaned CSV file
with open(cleaned_csv_file_path, 'w', newline='') as outfile:
    writer = csv.writer(outfile)
    writer.writerows(valid_rows)

print(f"Cleaned data saved to {cleaned_csv_file_path}.")

import os
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models, transforms
from PIL import Image
from sklearn.model_selection import train_test_split

# Load the cleaned styles DataFrame
styles_df = pd.read_csv('/content/myntradataset/styles_cleaned.csv')

# Specify the images directory
images_dir = '/content/myntradataset/images/'

# List all image files in the images directory
existing_images = set(os.listdir(images_dir))

# Create a new column with image filenames
styles_df['image_filename'] = styles_df['id'].astype(str) + '.jpg'

# Filter the DataFrame to keep only entries with existing images
styles_df_filtered = styles_df[styles_df['image_filename'].isin(existing_images)]

# Limit to the first 100 images
styles_df_filtered = styles_df_filtered.head(100)

# Factorize the labels (convert categories to integers)
styles_df_filtered['label_encoded'], unique_labels = pd.factorize(styles_df_filtered['masterCategory'])

# Create a custom dataset class
class FashionProductDataset(torch.utils.data.Dataset):
    def init(self, dataframe, img_dir, transform=None):
        self.dataframe = dataframe
        self.img_dir = img_dir
        self.transform = transform

    def len(self):
        return len(self.dataframe)

    def getitem(self, idx):
        product_id = self.dataframe.iloc[idx]['id']
        label = self.dataframe.iloc[idx]['label_encoded']

        img_path = os.path.join(self.img_dir, f'{product_id}.jpg')
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(label)  # Convert label to tensor

# Image transformations (further downscaling to reduce memory)
transform = transforms.Compose([
    transforms.Resize((64, 64), Image.LANCZOS),  # Smaller size to optimize RAM
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create dataset with the filtered DataFrame (only 100 images)
image_dataset = FashionProductDataset(dataframe=styles_df_filtered, img_dir=images_dir, transform=transform)

# Split the dataset into training and validation sets
train_data, val_data = train_test_split(image_dataset, test_size=0.2, random_state=42)

# Optimized DataLoader (smaller batch size, reduced workers)
train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=1, pin_memory=True)
val_loader = DataLoader(val_data, batch_size=8, shuffle=False, num_workers=1, pin_memory=True)

# Load pre-trained ResNet50 model
resnet_model = models.resnet50(pretrained=True)

# Modify the final layer to match the number of classes
num_classes = styles_df_filtered['label_encoded'].nunique()  # Count unique categories
resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)

# Move the model to device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
resnet_model = resnet_model.to(device)

# Define loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.001)

# Training loop (consider mixed precision for further optimization if using GPU)
num_epochs = 10
for epoch in range(num_epochs):
    resnet_model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)  # Labels are now tensors, so this will work

        # Forward pass
        outputs = resnet_model(images)
        loss = criterion(outputs, labels)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

# Save the image feature extractor (excluding the final classification layer)
image_feature_extractor = nn.Sequential(*list(resnet_model.children())[:-1])  # Exclude the final fully connected layer

# Save the feature extractor model
torch.save(image_feature_extractor.state_dict(), 'resnet50_feature_extractor.pth')

print("Feature extractor saved successfully.")

import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# Load the pre-trained ResNet50 feature extractor (excluding the final classification layer)
resnet_model = models.resnet50(pretrained=True)  # Use pretrained weights
resnet_model.fc = nn.Identity()  # Remove the final fully connected layer by setting it to Identity

# Load the state_dict (saved feature extractor weights)
resnet_model.load_state_dict(torch.load('/content/resnet50_feature_extractor.pth'), strict=False)

# Set the model to evaluation mode
resnet_model.eval()

# Move the model to the correct device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
resnet_model = resnet_model.to(device)

# Image transformations (same as during training)
transform = transforms.Compose([
    transforms.Resize((64, 64), Image.LANCZOS),  # Ensure the images are resized to match training input
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Function to extract features from a single image
def extract_features(image_path, model, device):
    # Load and transform the image
    image = Image.open(image_path).convert('RGB')
    image = transform(image)
    image = image.unsqueeze(0)  # Add batch dimension

    # Move the image to the correct device
    image = image.to(device)

    # Extract features
    with torch.no_grad():  # No need for gradient calculation
        features = model(image)

    return features.cpu().numpy()  # Move the features back to CPU and convert to NumPy

# Example usage:
image_path = '/content/myntradataset/images/7329.jpg'  # Path to the image you want to extract features from
features = extract_features(image_path, resnet_model, device)

print("Extracted features shape:", features.shape)
print("Extracted features:", features)